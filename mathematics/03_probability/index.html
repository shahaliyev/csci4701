
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Probability theory provides the mathematical foundation for reasoning under uncertainty. This page introduces the core probability concepts used in deep learning, including random variables, probability distributions, conditional probability, Bayes' rule, likelihood, expectation, and common distributions and functions used to model data, noise, and model outputs.
">
      
      
      
        <link rel="canonical" href="https://shahaliyev.org/csci4701/mathematics/03_probability/">
      
      
        <link rel="prev" href="../02_linear_algebra/">
      
      
        <link rel="next" href="../04_information/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Probability Theory - CSCI 4701 Deep Learning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
      <link rel="stylesheet" href="../../assets/styles/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-S1QRRQG9BM"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-S1QRRQG9BM",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-S1QRRQG9BM",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#probability-theory" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="CSCI 4701 Deep Learning" class="md-header__button md-logo" aria-label="CSCI 4701 Deep Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CSCI 4701 Deep Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Probability Theory
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/shahaliyev/csci4701" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../course/spring-2026/01_syllabus/" class="md-tabs__link">
          
  
  
  Course

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../introduction/01_deep_learning/" class="md-tabs__link">
          
  
  
  Introduction

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../notebooks/" class="md-tabs__link">
          
  
  
  Notebooks

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
  Mathematics

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../supplementary/" class="md-tabs__link">
          
  
  
  Supplementary

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../advanced/" class="md-tabs__link">
          
  
  
  Advanced

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="CSCI 4701 Deep Learning" class="md-nav__button md-logo" aria-label="CSCI 4701 Deep Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    CSCI 4701 Deep Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/shahaliyev/csci4701" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Course
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Course
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_1" >
        
          
          <label class="md-nav__link" for="__nav_1_1" id="__nav_1_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Spring 2026
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Spring 2026
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course/spring-2026/01_syllabus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Syllabus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course/spring-2026/02_assesments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Assessments
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course/spring-2026/03_project/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Introduction
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../introduction/01_deep_learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Deep Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../introduction/02_machine_learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../introduction/03_resources/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Resources
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Notebooks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Notebooks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Lecture Notebooks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/01_backprop/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    01. From Derivatives to Backpropagation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/02_neural_network/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    02. From Neuron to Neural Network
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/03_cnn_torch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    03. From Kernel to Convolutional Neural Network
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/04_regul_optim/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    04. Regularization and Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/05_batchnorm_resnet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    05. Batch Normalization and Residual Blocks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/06_nn_ngram/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    06. Neural Network N-Gram Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/07_vae/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    07. Variational Autoencoders (VAE)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Mathematics
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Mathematics
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Mathematics of Deep Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Calculus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02_linear_algebra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Linear Algebra
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Probability Theory
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Probability Theory
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#kolmogorov-axioms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kolmogorov Axioms
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#two-views-of-probability" class="md-nav__link">
    <span class="md-ellipsis">
      
        Two Views of Probability
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-variables" class="md-nav__link">
    <span class="md-ellipsis">
      
        Random Variables
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probability-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Probability Distributions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#joint-and-marginal-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Joint and Marginal Distributions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conditional-probability" class="md-nav__link">
    <span class="md-ellipsis">
      
        Conditional Probability
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#independence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Independence
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chain-rule" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chain Rule
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#independent-and-identically-distributed" class="md-nav__link">
    <span class="md-ellipsis">
      
        Independent and Identically Distributed
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayes-rule" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bayes' Rule
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#expectation-variance-covariance" class="md-nav__link">
    <span class="md-ellipsis">
      
        Expectation, Variance, Covariance
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-probability-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Probability Distributions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Probability Distributions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#uniform" class="md-nav__link">
    <span class="md-ellipsis">
      
        Uniform
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bernoulli" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bernoulli
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#categorical-multinoulli" class="md-nav__link">
    <span class="md-ellipsis">
      
        Categorical (Multinoulli)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normal-gaussian" class="md-nav__link">
    <span class="md-ellipsis">
      
        Normal (Gaussian)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exponential" class="md-nav__link">
    <span class="md-ellipsis">
      
        Exponential
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace" class="md-nav__link">
    <span class="md-ellipsis">
      
        Laplace
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dirac-delta-and-empirical-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dirac Delta and Empirical Distribution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#empirical" class="md-nav__link">
    <span class="md-ellipsis">
      
        Empirical
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixture-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mixture Distributions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Functions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sigmoid
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu" class="md-nav__link">
    <span class="md-ellipsis">
      
        ReLU
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softplus" class="md-nav__link">
    <span class="md-ellipsis">
      
        Softplus
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logarithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Logarithm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax" class="md-nav__link">
    <span class="md-ellipsis">
      
        Softmax
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#measure-theory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Measure Theory
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04_information/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Information Theory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_prob_modeling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Probabilistic Modeling
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Supplementary
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Supplementary
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../supplementary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Suppementary Material
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../supplementary/pca/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Principal Component Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../supplementary/svd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Singular Value Decomposition
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Advanced
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Advanced
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Advanced Material
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#kolmogorov-axioms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kolmogorov Axioms
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#two-views-of-probability" class="md-nav__link">
    <span class="md-ellipsis">
      
        Two Views of Probability
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-variables" class="md-nav__link">
    <span class="md-ellipsis">
      
        Random Variables
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probability-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Probability Distributions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#joint-and-marginal-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Joint and Marginal Distributions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conditional-probability" class="md-nav__link">
    <span class="md-ellipsis">
      
        Conditional Probability
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#independence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Independence
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chain-rule" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chain Rule
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#independent-and-identically-distributed" class="md-nav__link">
    <span class="md-ellipsis">
      
        Independent and Identically Distributed
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayes-rule" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bayes' Rule
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#expectation-variance-covariance" class="md-nav__link">
    <span class="md-ellipsis">
      
        Expectation, Variance, Covariance
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-probability-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Probability Distributions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Probability Distributions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#uniform" class="md-nav__link">
    <span class="md-ellipsis">
      
        Uniform
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bernoulli" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bernoulli
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#categorical-multinoulli" class="md-nav__link">
    <span class="md-ellipsis">
      
        Categorical (Multinoulli)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normal-gaussian" class="md-nav__link">
    <span class="md-ellipsis">
      
        Normal (Gaussian)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exponential" class="md-nav__link">
    <span class="md-ellipsis">
      
        Exponential
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace" class="md-nav__link">
    <span class="md-ellipsis">
      
        Laplace
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dirac-delta-and-empirical-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dirac Delta and Empirical Distribution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#empirical" class="md-nav__link">
    <span class="md-ellipsis">
      
        Empirical
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixture-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mixture Distributions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Functions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sigmoid
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu" class="md-nav__link">
    <span class="md-ellipsis">
      
        ReLU
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softplus" class="md-nav__link">
    <span class="md-ellipsis">
      
        Softplus
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logarithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Logarithm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax" class="md-nav__link">
    <span class="md-ellipsis">
      
        Softmax
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#measure-theory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Measure Theory
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="probability-theory">Probability Theory</h1>
<div style="margin:.3rem 0 1rem;font-size:.9em;color:#555;display:flex;align-items:center;gap:.35rem;font-family:monospace">
  <time datetime="2026-02-07">7 Feb 2026</time>
</div>

<p>Probability theory is the mathematical framework for reasoning under uncertainty. In artificial intelligence, probability is used in two main ways: (i) as a guide for how an intelligent system should reason under uncertainty, and (ii) as a tool for analyzing and understanding the behavior of learning algorithms. <a href="../../introduction/01_deep_learning">Deep learning</a> relies on probability because real-world data is noisy, incomplete, and never fully deterministic, so uncertainty is unavoidable.  </p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>The following source was consulted in preparing this material: Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <em>Deep Learning</em>. MIT Press. <a href="https://www.deeplearningbook.org/contents/prob.html">Chapter 3: Probability and Information Theory</a>.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>Some concepts in this material are simplified for pedagogical purposes. These simplifications slightly reduce precision but preserve the core ideas relevant to deep learning.</p>
</div>
<h2 id="kolmogorov-axioms">Kolmogorov Axioms</h2>
<p>Probability is a consistent system governed by a small set of rules (axioms) that prevent contradictions. In modern mathematics, these rules are usually given by the axioms introduced by Kolmogorov<sup id="fnref:kolmogorov"><a class="footnote-ref" href="#fn:kolmogorov">1</a></sup>. The three axioms define probability as a function <span class="arithmatex">\(P(\cdot)\)</span> that assigns a number to each event in a set of valid events. For any event <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(B\)</span>, a probability function must satisfy the following basic rules:</p>
<ul>
<li>It can never assign a negative value: <span class="arithmatex">\(P(A) \ge 0\)</span></li>
<li>It must assign probability <span class="arithmatex">\(1\)</span> to a certain event: <span class="arithmatex">\(P(\text{certain event}) = 1\)</span></li>
<li>If two events cannot happen at the same time (<span class="arithmatex">\(A \cap B = \emptyset\)</span>), their probabilities add up: <span class="arithmatex">\(P(A \cup B)=P(A)+P(B)\)</span>.</li>
</ul>
<p>These axioms guarantee that probability remains logically consistent.<sup id="fnref:dutchbook"><a class="footnote-ref" href="#fn:dutchbook">2</a></sup> Probability assigns numbers between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span> to events in order to represent how plausible those events are, given some assumptions or information. A value of <span class="arithmatex">\(0\)</span> means the event is impossible under the assumed model, a value of <span class="arithmatex">\(1\)</span> means it is certain, and intermediate values represent partial uncertainty.</p>
<h2 id="two-views-of-probability">Two Views of Probability</h2>
<p>Historically, probability was first developed to describe repeatable experiments, such as rolling dice, drawing cards, or observing outcomes in games of chance. Under this interpretation, called <strong>frequentist probability</strong>, <span class="arithmatex">\(P(A)\)</span> represents the long-run fraction of times event <span class="arithmatex">\(A\)</span> occurs if the experiment were repeated infinitely many times. For example, <span class="arithmatex">\(P(\text{heads})=0.5\)</span> means that if we toss a fair coin a very large number of times, about half of the tosses will result in heads.<sup id="fnref:frequentist"><a class="footnote-ref" href="#fn:frequentist">3</a></sup></p>
<p>Later, probability began to be used in a broader sense: not only for repeatable experiments, but also for reasoning about unique situations where repetition is impossible. For example, a doctor may assign a probability that a patient has a disease, even though we cannot create infinitely many identical copies of the patient. In this interpretation, called <strong>Bayesian probability</strong>, probability measures a <em>degree of belief</em> given incomplete information.</p>
<p>Although the interpretations differ, the same probability formulas apply to both. The axioms and rules of probability provide a consistent framework for reasoning under uncertainty, regardless of whether probability is interpreted as frequency or degree of belief.</p>
<h2 id="random-variables">Random Variables</h2>
<p>In probability theory, we rarely assign probabilities directly to raw outcomes. Instead, we define a <strong>random variable</strong>, which is a variable whose value depends on the outcome of an uncertain process. A random variable does not necessarily mean the process is truly random. It simply means that, from our perspective, the value is unknown until the outcome is observed. Random variables can be:</p>
<ul>
<li><strong>Discrete</strong>, meaning they can take only a finite or <a href="https://en.wikipedia.org/wiki/Countable_set">countably infinite</a> set of values (e.g. <span class="arithmatex">\(0,1,2,\dots\)</span>).</li>
<li><strong>Continuous</strong>, meaning they can take any real value in an interval (e.g. any number in <span class="arithmatex">\([0,1]\)</span>).</li>
</ul>
<p>For example, the result of a coin toss can be modeled as a discrete random variable <span class="arithmatex">\(X \in \{0,1\}\)</span>, while the temperature measured by a sensor is naturally modeled as a continuous random variable. In probability notation, we usually write a random variable using a capital letter such as <span class="arithmatex">\(X\)</span>, and a specific realized value using a lowercase letter such as <span class="arithmatex">\(x\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In deep learning, we often model data as random variables. For example, an image can be treated as a random variable <span class="arithmatex">\(X\)</span>, and its label (such as "cat" or "dog") as another random variable <span class="arithmatex">\(Y\)</span>. The goal of learning is then to discover patterns in how these random variables relate to each other.</p>
</div>
<h2 id="probability-distributions">Probability Distributions</h2>
<p>A random variable by itself only describes what values are possible. To reason quantitatively, we must also specify a <strong>probability distribution</strong>, which assigns probabilities to the different values the random variable can take.</p>
<p>Once the outcome is observed, the random variable takes a specific value. If a random variable is discrete, its distribution is described by a <strong>probability mass function (PMF)</strong>, denoted by <span class="arithmatex">\(P(X=x)\)</span>. It assigns a probability to each possible value, such that:</p>
<ul>
<li><span class="arithmatex">\(0 \le P(X=x) \le 1\)</span></li>
<li><span class="arithmatex">\(\sum_x P(X=x) = 1\)</span></li>
</ul>
<p>If a random variable is continuous, its distribution is described by a <strong>probability density function (PDF)</strong>, denoted by <span class="arithmatex">\(p(x)\)</span>. The PDF must satisfy:</p>
<ul>
<li><span class="arithmatex">\(p(x) \ge 0\)</span></li>
<li><span class="arithmatex">\(\int_{-\infty}^{\infty} p(x)\,dx = 1\)</span></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>For continuous variables, <span class="arithmatex">\(p(x)\)</span> is a <em>density</em>, not a probability. The value <span class="arithmatex">\(p(x)\)</span> can be greater than <span class="arithmatex">\(1\)</span>. Probabilities are obtained only by integrating over an interval:
$$
P(a \le X \le b) = \int_a^b p(x)\,dx
$$
The probability of observing any exact value <span class="arithmatex">\(X=x\)</span> is always <span class="arithmatex">\(0\)</span>. For example, if <span class="arithmatex">\(X\)</span> represents a real-valued measurement such as temperature, the probability of observing exactly <span class="arithmatex">\(20.000^\circ\)</span> is essentially zero, because the measurement could always end up being <span class="arithmatex">\(19.999\)</span> or <span class="arithmatex">\(20.001\)</span> instead. Only intervals have non-zero probability, such as <span class="arithmatex">\(P(19.9 \le X \le 20.1)\)</span>.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For integration and related topics, see the page dedicated to deep learning <a href="../01_calculus">Calculus</a>.</p>
</div>
<h2 id="joint-and-marginal-distributions">Joint and Marginal Distributions</h2>
<p>So far, we have described probability distributions over a single random variable. In many real problems, we must model multiple random variables at the same time. The probability distribution over two variables <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> together is called the <strong>joint distribution</strong>. If <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are discrete, the joint distribution is written as:
<span class="arithmatex">\(P(X=x, Y=y).\)</span>
If <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are continuous, the joint distribution is written as a joint density:
<span class="arithmatex">\(p(x,y).\)</span></p>
<p>Often, we are only interested in the distribution of one variable by itself. This is called the <strong>marginal distribution</strong>, and it can be obtained by summing (discrete case) or integrating (continuous case) over the other variable. For discrete variables:
$$
P(X=x) = \sum_y P(X=x, Y=y).
$$
For continuous variables:
$$
p(x) = \int p(x,y)\,dy.
$$</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Suppose <span class="arithmatex">\(X\)</span> represents the outcome of a coin toss (tails or heads), and <span class="arithmatex">\(Y\)</span> represents the number shown on a fair die (<span class="arithmatex">\(1\)</span> to <span class="arithmatex">\(6\)</span>). If we assume the coin toss does not affect the die roll (and vice versa), then each of the <span class="arithmatex">\(2 \times 6 = 12\)</span> outcomes is equally likely, so the joint distribution assigns probability <span class="arithmatex">\(1/12\)</span> to every possible pair:</p>
<table>
<thead>
<tr>
<th><span class="arithmatex">\(X \backslash Y\)</span></th>
<th><span class="arithmatex">\(1\)</span></th>
<th><span class="arithmatex">\(2\)</span></th>
<th><span class="arithmatex">\(3\)</span></th>
<th><span class="arithmatex">\(4\)</span></th>
<th><span class="arithmatex">\(5\)</span></th>
<th><span class="arithmatex">\(6\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>tails</td>
<td>1/12</td>
<td>1/12</td>
<td>1/12</td>
<td>1/12</td>
<td>1/12</td>
<td>1/12</td>
</tr>
<tr>
<td>heads</td>
<td>1/12</td>
<td>1/12</td>
<td>1/12</td>
<td>1/12</td>
<td>1/12</td>
<td>1/12</td>
</tr>
</tbody>
</table>
<p>To compute the marginal distribution of <span class="arithmatex">\(X\)</span>, we sum across each row:<sup id="fnref:marginal"><a class="footnote-ref" href="#fn:marginal">4</a></sup>
$$
P(X=\text{tails}) = \sum_{y=1}^{6} P(X=\text{tails},Y=y) = \frac{1}{2}.
$$</p>
<div class="admonition success">
<p class="admonition-title">Exercise</p>
<p>Compute the marginal distributions <span class="arithmatex">\(P(X=\text{heads})\)</span> and <span class="arithmatex">\(P(Y=1)\)</span>.</p>
</div>
</div>
<h2 id="conditional-probability">Conditional Probability</h2>
<p>In many situations, we are interested in the probability of an event given that another event has already occurred. This is called <strong>conditional probability</strong>. The conditional probability of <span class="arithmatex">\(A\)</span> given <span class="arithmatex">\(B\)</span> is denoted by <span class="arithmatex">\(P(A \mid B)\)</span>.</p>
<p>For discrete random variables <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span>, the conditional distribution of <span class="arithmatex">\(Y\)</span> given <span class="arithmatex">\(X\)</span> is defined as:
$$
P(Y=y \mid X=x) = \frac{P(X=x, Y=y)}{P(X=x)}.
$$</p>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>Many textbooks use shorthand notation such as <span class="arithmatex">\(P(y \mid x)\)</span> instead of <span class="arithmatex">\(P(Y=y \mid X=x)\)</span>. We will mostly use explicit notation for clarity.</p>
</div>
<p>For continuous random variables, we use probability densities instead:
$$
p(y \mid x) = \frac{p(x,y)}{p(x)}.
$$</p>
<p>These formulas are only defined when <span class="arithmatex">\(P(X=x)&gt;0\)</span> or <span class="arithmatex">\(p(x)&gt;0\)</span>, since we cannot condition on an event that never occurs.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Suppose <span class="arithmatex">\(X\)</span> is an image and <span class="arithmatex">\(Y\)</span> is its label. The joint distribution <span class="arithmatex">\(P(X,Y)\)</span> describes how often we encounter a specific image together with its correct label. The marginal distribution <span class="arithmatex">\(P(X)\)</span> describes what kinds of images appear in the world or in our dataset, regardless of their labels. The conditional distribution <span class="arithmatex">\(P(Y \mid X)\)</span> describes the probability of each label given a particular image. When we train a classifier, we are essentially training a model that takes an image <span class="arithmatex">\(x\)</span> and outputs estimates of probabilities like <span class="arithmatex">\(P(Y=\text{cat} \mid X=x)\)</span> and <span class="arithmatex">\(P(Y=\text{dog} \mid X=x)\)</span>, where <span class="arithmatex">\(x\)</span> could be a particular input image provided to our model.</p>
</div>
<p>Marginalization can also be written in a form that uses conditional probabilities. This is known as the <a href="https://en.wikipedia.org/wiki/Law_of_total_probability">law of total probability</a>. For discrete variables:</p>
<div style="overflow-x:auto; max-width:100%;">
$$
P(Y=y)
=
\sum_x P(Y=y \mid X=x)\,P(X=x).
$$
</div>

<p>For continuous variables:
$$
p(y)
=
\int p(y \mid x)\,p(x)\,dx.
$$</p>
<p>This identity is extremely important.</p>
<h2 id="independence">Independence</h2>
<p>In many problems, we work with multiple random variables. The relationship between these variables determines how complicated the joint distribution is. Two random variables <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are called <strong>independent</strong> if knowing the value of one gives no information about the other. Formally, <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are independent if their joint distribution factorizes into a product of marginals:
$$
P(X=x, Y=y) = P(X=x)\,P(Y=y).
$$</p>
<p>Equivalently, independence can be expressed using conditional probability:
$$
P(Y=y \mid X=x) = P(Y=y),
$$
meaning that observing <span class="arithmatex">\(X\)</span> does not change the probability of <span class="arithmatex">\(Y\)</span>. For continuous variables, the same definition applies using probability densities:
$$
p(x,y) = p(x)\,p(y).
$$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Independence is a very strong assumption. In real-world data, variables are often correlated. However, independence assumptions are extremely useful because they allow us to build computationally efficient models.</p>
</div>
<p>Sometimes variables are not independent in general, but become independent once we condition on a third variable. We say that <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are <strong>conditionally independent</strong> given <span class="arithmatex">\(Z\)</span> if:
$$
P(X=x, Y=y \mid Z=z) = \\ 
P(X=x \mid Z=z)\,P(Y=y \mid Z=z).
$$</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Suppose <span class="arithmatex">\(Z\)</span> represents whether it is raining. Let <span class="arithmatex">\(X\)</span> be whether the street is wet, and <span class="arithmatex">\(Y\)</span> be whether people are carrying umbrellas. In general, <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are strongly correlated: if the street is wet, umbrellas are more likely. However, once we condition on <span class="arithmatex">\(Z\)</span> (rain), the relationship mostly disappears: given that it is raining, the street being wet does not provide much additional information about umbrellas. This illustrates conditional independence: <span class="arithmatex">\(X \perp Y \mid Z\)</span>.</p>
</div>
<h2 id="chain-rule">Chain Rule</h2>
<p>Probability has its own chain rule. Even when random variables are not independent, we can still represent any joint distribution by repeatedly applying the definition of conditional probability. For two variables, the joint distribution can be rewritten as:
$$
P(X=x, Y=y) = P(Y=y \mid X=x)\,P(X=x).
$$</p>
<p>In general, for <span class="arithmatex">\(n\)</span> random variables <span class="arithmatex">\((X_1, X_2, \dots, X_n)\)</span>, we can expand the joint distribution as:
$$
P(X_1, X_2, \dots, X_n)
=
\prod_{i=1}^{n} P(X_i \mid X_1, \dots, X_{i-1}).
$$</p>
<p>This identity is called the <strong>chain rule</strong> of probability. It is simply a consequence of how conditional probability is defined.</p>
<p>The chain rule gives a valid factorization, but it is often too complex because each conditional distribution depends on many variables. Independence assumptions simplify the factorization. For example, if we assume <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are independent, then:
$$
P(X,Y) = P(X)\,P(Y).
$$</p>
<p>If we assume <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are conditionally independent given <span class="arithmatex">\(Z\)</span>, then:
$$
P(X,Y,Z) = P(X \mid Z)\,P(Y \mid Z)\,P(Z).
$$</p>
<p>This type of factorization is the foundation of many probabilistic models, including Bayesian networks and graphical models.</p>
<h2 id="independent-and-identically-distributed">Independent and Identically Distributed</h2>
<p>In deep learning, the most common simplifying assumption is that training examples are <strong>independent and identically distributed (i.i.d.)</strong>. Suppose we have a dataset of samples:
$$
{x^{(1)}, x^{(2)}, \dots, x^{(m)}}.
$$</p>
<p>The i.i.d. assumption means that each sample is generated independently of the others, and all samples come from the same underlying distribution. Formally, if each sample is drawn from the same distribution <span class="arithmatex">\(P(X)\)</span> and samples are independent, then the joint probability of the dataset factorizes as:
$$
P(x^{(1)}, x^{(2)}, \dots, x^{(m)})
=
\prod_{i=1}^{m} P(x^{(i)}).
$$</p>
<p>This assumption is extremely important because it makes learning feasible: it allows the likelihood of a dataset to be written as a product, and the log-likelihood as a sum.</p>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>The i.i.d. assumption is often violated in practice. Examples include time series, video frames, financial data, and datasets affected by distribution shift.   However, i.i.d. is still widely used because it provides a simple baseline model of how data is generated.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a href="../../notebooks/04_regul_optim">Stochastic gradient descent (SGD)</a> implicitly relies on the i.i.d. assumption: each mini-batch is treated as a random sample from the same distribution, so its gradient is assumed to approximate the full dataset gradient.</p>
</div>
<h2 id="bayes-rule">Bayes' Rule</h2>
<p>We have reached a crucial point in probability theory. Terminology can be dense and seem complicated, so I suggest spending some time here to clearly understand the concepts. You will frequently see the described terminology in deep learning literature. </p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For a visual intuition of Bayes' rule, see the video on <a href="https://www.youtube.com/watch?v=HZGCoVF3YvM">Bayes' theorem</a>.</p>
</div>
<p><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes rule</a> allows us to reverse conditional probabilities. It provides a way to compute the probability of a hypothesis after observing <strong>evidence</strong>. For discrete random variables, Bayes rule is:</p>
<div style="overflow-x:auto; max-width:100%;">
$$
P(X=x \mid Y=y) = \frac{P(Y=y \mid X=x)\,P(X=x)}{P(Y=y)}.
$$
</div>

<p>Here, <span class="arithmatex">\(P(X=x)\)</span> is called the <strong>prior</strong>. It describes how likely <span class="arithmatex">\(x\)</span> was before observing <span class="arithmatex">\(y\)</span>. The term <span class="arithmatex">\(P(Y=y \mid X=x)\)</span> is the <strong>likelihood</strong>. It measures how compatible the observation <span class="arithmatex">\(y\)</span> is with the hypothesis <span class="arithmatex">\(x\)</span>. The result <span class="arithmatex">\(P(X=x \mid Y=y)\)</span> is called the <strong>posterior</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The denominator <span class="arithmatex">\(P(Y=y)\)</span> acts as a normalization constant. It ensures that the posterior distribution <span class="arithmatex">\(P(X \mid Y=y)\)</span> sums to <span class="arithmatex">\(1\)</span> over all possible values of <span class="arithmatex">\(X\)</span>.  </p>
</div>
<p>For continuous random variables, we use probability densities instead:
$$
p(x \mid y) = \frac{p(y \mid x)\,p(x)}{p(y)}.
$$</p>
<p>The denominator <span class="arithmatex">\(p(y)\)</span> is the marginal probability density of observing <span class="arithmatex">\(y\)</span>. It is obtained by summing over all possible values of <span class="arithmatex">\(x\)</span> that could have produced <span class="arithmatex">\(y\)</span> (in the continuous case, summation becomes integration):
$$
p(y) = \int p(y \mid x)\,p(x)\,dx.
$$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This continuous form of Bayes' rule will become important for us later when discussing <a href="../../notebooks/07_vae">variational autoencoders</a>.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Consider a spam detection example. Let <span class="arithmatex">\(X\)</span> represent whether an email is spam (<span class="arithmatex">\(X=\text{spam}\)</span> or <span class="arithmatex">\(X=\text{not spam}\)</span>), and let <span class="arithmatex">\(Y\)</span> represent whether the email contains the phrase "win money" (<span class="arithmatex">\(Y=\text{yes}\)</span> or <span class="arithmatex">\(Y=\text{no}\)</span>). </p>
<p>Suppose only <span class="arithmatex">\(2\%\)</span> of all emails are spam, so the prior probability is <span class="arithmatex">\(P(\text{spam})=0.02\)</span> and <span class="arithmatex">\(P(\text{not spam})=0.98\)</span>. Now assume spam emails contain the phrase "win money" <span class="arithmatex">\(60\%\)</span> of the time, so <span class="arithmatex">\(P(\text{yes} \mid \text{spam})=0.60\)</span>, while normal emails contain it only <span class="arithmatex">\(1\%\)</span> of the time, so <span class="arithmatex">\(P(\text{yes} \mid \text{not spam})=0.01\)</span>. If we observe an email containing "win money", Bayes rule gives:
$$
P(\text{spam} \mid \text{yes})
=
\frac{P(\text{yes} \mid \text{spam})P(\text{spam})}
{P(\text{yes})}.
$$
The numerator is <span class="arithmatex">\(0.60 \cdot 0.02 = 0.012\)</span>. The denominator is computed by marginalization:
$$
P(\text{yes})
=
P(\text{yes} \mid \text{spam})P(\text{spam})
+ \\
P(\text{yes} \mid \text{not spam})P(\text{not spam})
= \\
0.60\cdot 0.02 + 0.01\cdot 0.98
=
0.0218.
$$
Therefore,
$$
P(\text{spam} \mid \text{yes}) = \frac{0.012}{0.0218} \approx 0.55.
$$
After observing the phrase, the probability that the email is spam jumps from <span class="arithmatex">\(2\%\)</span> to about <span class="arithmatex">\(55\%\)</span>. This illustrates Bayes rule as a mechanism for updating beliefs: the <a href="../05_prob_modeling">likelihood</a> tells us how strongly the evidence points toward spam, while the prior reflects how common spam is overall.</p>
</div>
<h2 id="expectation-variance-covariance">Expectation, Variance, Covariance</h2>
<p>So far, we have described probability distributions in terms of the probability of events. However, in machine learning we often want to summarize a distribution using a few meaningful numerical quantities. The most important of these are the <em>expectation (mean)</em>, the <em>variance</em>, and the <em>covariance</em>.</p>
<p>The <strong>expectation</strong> (or expected value) of a function <span class="arithmatex">\(f(X)\)</span> is the average value of <span class="arithmatex">\(f(X)\)</span> when <span class="arithmatex">\(X\)</span> is sampled from its distribution. If <span class="arithmatex">\(X\)</span> is discrete:
$$
\mathbb{E}[f(X)]
=
\sum_x P(X=x)\,f(x).
$$</p>
<p>If <span class="arithmatex">\(X\)</span> is continuous:
$$
\mathbb{E}[f(X)]
=
\int p(x)\,f(x)\,dx.
$$</p>
<p>If we set <span class="arithmatex">\(f(X)=X\)</span>, we obtain the expected value of the random variable itself:
$
\mathbb{E}[X].
$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Expectations are the probabilistic version of weighted averages. The probability distribution acts as the weights. For example, the ordinary average of <span class="arithmatex">\(n\)</span> numbers <span class="arithmatex">\(x_1, x_2, \dots, x_n\)</span> is: <span class="arithmatex">\(\frac{1}{n}\sum_{i=1}^n x_i.\)</span>
This is exactly the expectation of a discrete random variable that takes value <span class="arithmatex">\(x_i\)</span> with uniform probability <span class="arithmatex">\(P(X=x_i)=\frac{1}{n}\)</span> (e.g. fair dice):
$$
\mathbb{E}[X] = \sum_{i=1}^n P(X=x_i)\,x_i = \sum_{i=1}^n \frac{1}{n}x_i = \frac{1}{n}\sum_{i=1}^n x_i.
$$</p>
</div>
<p>Expectation has an extremely useful property: it is <a href="../02_linear_algebra">linear</a>. For constants <span class="arithmatex">\(\alpha\)</span> and <span class="arithmatex">\(\beta\)</span>:
$$
\mathbb{E}[\alpha f(X) + \beta g(X)]
=
\alpha \mathbb{E}[f(X)] + \beta \mathbb{E}[g(X)].
$$</p>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>Linearity holds even when <span class="arithmatex">\(f(X)\)</span> and <span class="arithmatex">\(g(X)\)</span> are dependent. This is one of the most powerful tools in probability.</p>
</div>
<p>The <strong>variance</strong> measures how spread out a random variable is around its mean. In other words, it tells us whether values are tightly clustered near the average or whether they fluctuate widely. It is defined as:
$$
\mathrm{Var}(X)
=
\mathbb{E}\Big[(X - \mathbb{E}[X])^2\Big].
$$</p>
<p>Here, <span class="arithmatex">\((X - \mathbb{E}[X])\)</span> is the deviation from the mean. If <span class="arithmatex">\(X\)</span> usually stays close to <span class="arithmatex">\(\mathbb{E}[X]\)</span>, the variance is small. If <span class="arithmatex">\(X\)</span> often takes values far from <span class="arithmatex">\(\mathbb{E}[X]\)</span>, the variance is large.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We square deviations because (i) it prevents positive and negative deviations from canceling out, (ii) it penalizes large deviations more strongly, and (iii) it leads to clean mathematical formulas that are easy to analyze and optimize.<br />
Using absolute deviation is possible but less convenient in theory.</p>
</div>
<p>The <strong>standard deviation</strong> is defined as:
$$
\sigma(X) = \sqrt{\mathrm{Var}(X)}.
$$ 
It is often more intuitive than variance because it is measured in the same scale as the original variable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Variance can also be rewritten in a form that is often easier to compute:
$$
\mathrm{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2.
$$
This identity is widely used in probability derivations and appears frequently in machine learning theory.</p>
</div>
<p>The <strong>covariance</strong> measures how two random variables vary together. It captures whether they tend to increase and decrease at the same time. It is defined as:
$$
\mathrm{Cov}(X,Y)
=
\mathbb{E}\Big[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])\Big].
$$</p>
<p>If both <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are usually above their means at the same time (or below their means at the same time), the covariance becomes positive. If one is usually above its mean when the other is below its mean, the covariance becomes negative.</p>
<ul>
<li>If <span class="arithmatex">\(\mathrm{Cov}(X,Y) &gt; 0\)</span>, <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> tend to move in the same direction.</li>
<li>If <span class="arithmatex">\(\mathrm{Cov}(X,Y) &lt; 0\)</span>, <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> tend to move in opposite directions.</li>
<li>If <span class="arithmatex">\(\mathrm{Cov}(X,Y) = 0\)</span>, <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> have no linear relationship.</li>
</ul>
<p>Covariance measures <em>linear</em> dependence only. It is possible for two variables to be strongly dependent in a nonlinear way while still having covariance equal to zero. If <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are independent, then: <span class="arithmatex">\(\mathrm{Cov}(X,Y)=0.\)</span> However, the reverse is not always true: <span class="arithmatex">\(\mathrm{Cov}(X,Y)=0\)</span> does <strong>not</strong> guarantee independence.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Suppose <span class="arithmatex">\(X\)</span> is uniformly distributed on <span class="arithmatex">\([-1,1]\)</span>, and let <span class="arithmatex">\(Y=X^2\)</span>. Then <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are clearly dependent, because knowing <span class="arithmatex">\(X\)</span> determines <span class="arithmatex">\(Y\)</span>. However, their covariance is still <span class="arithmatex">\(0\)</span>, because positive and negative values of <span class="arithmatex">\(X\)</span> cancel out.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Covariance depends on scale. A scale-independent version is the <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">correlation coefficient</a> (Pearson correlation):
$$
\rho(X,Y)
=
\frac{\mathrm{Cov}(X,Y)}{\sigma(X)\sigma(Y)},
\qquad
\sigma(X)=\sqrt{\mathrm{Var}(X)}.
$$
It is always bounded:
$$
-1 \le \rho(X,Y) \le 1.
$$
Correlation measures only <em>linear</em> dependence, so <span class="arithmatex">\(\rho(X,Y)=0\)</span> does not imply independence.</p>
</div>
<p>In machine learning, we often deal with random vectors. If <span class="arithmatex">\(X \in \mathbb{R}^n\)</span> is a random vector, then its <strong>covariance matrix</strong> is an <span class="arithmatex">\(n \times n\)</span> matrix defined as:
$$
\mathrm{Cov}(X)_{i,j} = \mathrm{Cov}(X_i, X_j).
$$</p>
<p>The diagonal elements represent variances:
$$
\mathrm{Cov}(X_i, X_i) = \mathrm{Var}(X_i).
$$</p>
<p>The off-diagonal elements represent how different dimensions vary together:
$
\mathrm{Cov}(X_i, X_j).
$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The covariance matrix is a compact way to describe how multiple variables relate to each other. For example, if your dataset has three features (height, weight, age), then the covariance matrix is a <span class="arithmatex">\(3 \times 3\)</span> matrix:
<div style="overflow-x:auto; max-width:100%;">
$$
\Sigma =
\begin{bmatrix}
\mathrm{Var}(\text{height}) &amp; \mathrm{Cov}(\text{height},\text{weight}) &amp; \mathrm{Cov}(\text{height},\text{age}) \\
\mathrm{Cov}(\text{weight},\text{height}) &amp; \mathrm{Var}(\text{weight}) &amp; \mathrm{Cov}(\text{weight},\text{age}) \\
\mathrm{Cov}(\text{age},\text{height}) &amp; \mathrm{Cov}(\text{age},\text{weight}) &amp; \mathrm{Var}(\text{age})
\end{bmatrix}.
$$
</div>
The diagonal entries measure the spread of each feature (variance), while the off-diagonal entries measure whether two features increase or decrease together (covariance).</p>
</div>
<h2 id="common-probability-distributions">Common Probability Distributions</h2>
<p>Many probability distributions exist, but only a small number appear repeatedly in deep learning and machine learning. These distributions are used to model labels, noise, uncertainty in model outputs, etc. In practice, choosing an appropriate distribution is part of defining the assumptions of a model. A good probabilistic model is not just about fitting data  it is also about choosing a distribution that matches the structure of the problem.</p>
<h3 id="uniform">Uniform</h3>
<p><a href="https://www.acsu.buffalo.edu/~adamcunn/probability/uniform.html">Uniform distribution</a> simply assigns equal probability to every possible outcome. For a discrete uniform distribution over <span class="arithmatex">\(k\)</span> values:
$$
P(X=i)=\frac{1}{k}.
$$</p>
<p>For a continuous uniform distribution over an interval <span class="arithmatex">\([a,b]\)</span>:
$$
p(x)=\frac{1}{b-a},
\qquad x \in [a,b].
$$</p>
<p>Outside the interval, the density is zero.</p>
<h3 id="bernoulli">Bernoulli</h3>
<p><a href="https://www.acsu.buffalo.edu/~adamcunn/probability/bernoulli.html">Bernoulli distribution</a> is also simple. It models a binary random variable: <span class="arithmatex">\(X \in \{0,1\}.\)</span> It is controlled by a single parameter <span class="arithmatex">\(\phi \in [0,1]\)</span>, representing the probability of success:
$$
P(X=1) = \phi,
\qquad
P(X=0) = 1-\phi,
$$</p>
<p>which can also be written compactly as:
$$
P(X=x) = \phi^x (1-\phi)^{1-x}.
$$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We can derive the expectation and variance of a Bernoulli random variable directly from the definition of expectation. Since <span class="arithmatex">\(X \in \{0,1\}\)</span>, we have:
<div style="overflow-x:auto; max-width:100%;">
$$
\mathbb{E}[X]
=
\sum_{x\in{0,1}} xP(X=x)
= 
0\cdot P(X=0) + 1\cdot P(X=1)
=
\phi.
$$
</div></p>
<p>To compute the variance, we use:
$$
\mathrm{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2.
$$
But since <span class="arithmatex">\(X\)</span> is binary, <span class="arithmatex">\(X^2=X\)</span>, so:
$$
\mathbb{E}[X^2] = \mathbb{E}[X] = \phi.
$$
Therefore,
$$
\mathrm{Var}(X)
=
\phi - \phi^2
=
\phi(1-\phi).
$$</p>
</div>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Suppose we model whether an <a href="../../notebooks/03_cnn_torch">MNIST</a> image is the digit <span class="arithmatex">\(3\)</span> as a Bernoulli random variable: <span class="arithmatex">\(Y \in \{0,1\},\)</span> where <span class="arithmatex">\(Y=1\)</span> means the image is a <span class="arithmatex">\(3\)</span> and <span class="arithmatex">\(Y=0\)</span> means it is not. If we assume the dataset defines an underlying distribution <span class="arithmatex">\(P(Y)\)</span>, then we can write:
$$
Y \sim \mathrm{Bernoulli}(\phi),
$$
which implies we <strong>sample</strong> from the distribution. If <span class="arithmatex">\(10\%\)</span> of the MNIST dataset images are <span class="arithmatex">\(3\)</span>, then:
$$ P(Y=1)=\phi = 0.1.$$ </p>
<p>In binary classification, a neural network often outputs a probability estimate:
$$
\hat{\phi}(x) \approx P(Y=1 \mid X=x),
$$
where <span class="arithmatex">\(x\)</span> is an input image. The prediction can then be interpreted as sampling from a Bernoulli distribution:
$$
\hat{Y} \sim \mathrm{Bernoulli}(\hat{\phi}(x)).
$$</p>
<p>For instance, if the model outputs <span class="arithmatex">\(\hat{\phi}(x)=0.92\)</span>, it means the model assigns a <span class="arithmatex">\(92\%\)</span> probability that the given MNIST image is a <span class="arithmatex">\(3\)</span>.</p>
</div>
<h3 id="categorical-multinoulli">Categorical (Multinoulli)</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical distribution</a> (also called the multinoulli distribution<sup id="fnref:multinoulli"><a class="footnote-ref" href="#fn:multinoulli">5</a></sup>) generalizes Bernoulli to more than two outcomes. It models a discrete variable with <span class="arithmatex">\(k\)</span> possible states:
$$
X \in {1,2,\dots,k}.
$$</p>
<p>It is parameterized by a probability vector:
$$
p = (p_1, p_2, \dots, p_k),
\qquad
\sum_{i=1}^k p_i = 1.
$$</p>
<p>The probability mass function is:
$$
P(X=i) = p_i.
$$</p>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>Do not confuse the multinoulli (categorical) distribution with the <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial distribution</a>. A categorical distribution describes a single outcome from <span class="arithmatex">\(k\)</span> categories (one draw). A multinomial distribution describes a vector of counts showing how many times each category occurs after <span class="arithmatex">\(n\)</span> draws. In other words, multinomial is not another name for categorical  it is a different distribution with a different type of output, which can be seen as a special case of the multinomial distribution when <span class="arithmatex">\(n=1\)</span>.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>In MNIST digit classification, the label for a single image is modeled as a categorical random variable:
$$
Y \in {0,1,2,\dots,9}.
$$
We can write <span class="arithmatex">\(Y \sim \mathrm{Categorical}(p),\)</span> where:
$$
p = (p_0,p_1,\dots,p_9),
\qquad
\sum_{i=0}^9 p_i = 1.
$$</p>
<p>A neural network outputs a probability vector using <a href="../../notebooks/06_nn_ngram">softmax</a>:
$$
\hat{p}(x) \approx P(Y \mid X=x).
$$
For example, if the model outputs <span class="arithmatex">\(\hat{p}_3(x)=0.85\)</span>, this means the model assigns an <span class="arithmatex">\(85\%\)</span> probability that the image is the digit <span class="arithmatex">\(3\)</span>.</p>
<p>Now suppose we take a <a href="../../04_regul_optim">mini-batch</a> of <span class="arithmatex">\(n=100\)</span> MNIST images and count how many of each digit appear in the batch. We might obtain a count vector such as:
$$
(c_0,c_1,\dots,c_9) = (8,11,9,7,10,12,6,14,13,10),
$$
where
$
\sum_{i=0}^9 c_i = 100.
$ This count vector is not categorical anymore. It is modeled by a multinomial distribution:
$$
(c_0,c_1,\dots,c_9) \sim \mathrm{Multinomial}(n=100, p).
$$</p>
<p>In other words, categorical (multinoulli) describes <em>one label</em>, while multinomial describes <em>counts of labels across many samples</em>.</p>
</div>
<div class="admonition success">
<p class="admonition-title">Exercise</p>
<p>Let <span class="arithmatex">\(Y \sim \mathrm{Categorical}(p)\)</span> with <span class="arithmatex">\(k\)</span> categories, and represent the label as a one-hot vector <span class="arithmatex">\(e_Y \in \mathbb{R}^k\)</span>. Show that <span class="arithmatex">\(\mathbb{E}[e_Y] = p.\)</span> Then derive the covariance matrix <span class="arithmatex">\(\mathrm{Cov}(e_Y)\)</span>.</p>
</div>
<h3 id="normal-gaussian">Normal (Gaussian)</h3>
<p><a href="https://www.acsu.buffalo.edu/~adamcunn/probability/normal.html">Normal distribution</a>, also called Gaussian distribution<sup id="fnref:gauss"><a class="footnote-ref" href="#fn:gauss">6</a></sup>, is the most important continuous distribution in machine learning. It is defined as:
$$
\mathcal{N}(x;\mu,\sigma^2)
=
\frac{1}{\sqrt{2\pi\sigma^2}}
\exp\Big(-\frac{(x-\mu)^2}{2\sigma^2}\Big).
$$</p>
<p>Here, <span class="arithmatex">\(\mu\)</span> is the mean (center), <span class="arithmatex">\(\sigma^2\)</span> is the variance (spread), and <span class="arithmatex">\(\sigma\)</span> is the standard deviation of the distribution.</p>
<figure>
  <img src="../../assets/images/probability/normal_std.svg" alt="Normal (Gaussian) distribution standard deviation" style="max-width: 100%; height: auto;">
  <figcaption style="margin-top: 0.5em; font-size: 0.9em; opacity: 0.85;">
    For the normal distribution, the values less than one standard deviation from the mean account for 68.27% of the set; while two standard deviations from the mean account for 95.45%; and three standard deviations account for 99.73% ~ <a href="//commons.wikimedia.org/wiki/User:Mwtoews" title="User:Mwtoews">M. W. Toews</a> - <span class="int-own-work" lang="en">Own work</span>, based (in concept) on figure by Jeremy Kemp, on 2005-02-09, <a href="https://creativecommons.org/licenses/by/2.5" title="Creative Commons Attribution 2.5">CC BY 2.5</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=1903871">Link</a>
  </figcaption>
</figure>

<p>This distribution has a characteristic <em>bell curve</em> shape: values near <span class="arithmatex">\(\mu\)</span> are most likely, and values far from <span class="arithmatex">\(\mu\)</span> become increasingly rare.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The normal distribution is called <em>normal</em> because it became the standard default model for random measurement errors and noise in many scientific fields. For example, if you repeatedly measure the same quantity (temperature, weight, sensor voltage, satellite pixel reflectance), the errors often cluster around <span class="arithmatex">\(0\)</span>, while large errors are rare. The normal distribution captures exactly this pattern: small deviations are common, large deviations happen but are uncommon. </p>
<p>This idea also appears in everyday life: most human characteristics such as height, reaction time, exam scores, and typing speed tend to cluster around an average, with fewer people being extremely low or extremely high. While not everything in nature is perfectly Gaussian, the normal distribution often provides a good first approximation of "typical variation."</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem (CLT)</a> says that when many small independent random effects add together, their sum tends to become approximately Gaussian, even if the individual effects are not Gaussian. For example, the final value of a noisy measurement is often the sum of many tiny disturbances: sensor imperfections, rounding, thermal noise, vibration, lighting changes, etc. Even if each disturbance has its own distribution, the combined noise often looks normal.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Law_of_large_numbers">law of large numbers (LLN)</a> explains why averages become stable. If we sample <span class="arithmatex">\(X_1,X_2,\dots,X_n\)</span> from the same distribution and compute the average: 
<span class="arithmatex">\(\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i,\)</span>
then <span class="arithmatex">\(\bar{X}_n\)</span> tends to get closer to the true mean <span class="arithmatex">\(\mathbb{E}[X]\)</span> as <span class="arithmatex">\(n\)</span> becomes large.  </p>
<p>A simple example is coin tossing: with only <span class="arithmatex">\(10\)</span> tosses, the fraction of heads may be far from <span class="arithmatex">\(0.5\)</span>, but with <span class="arithmatex">\(10,000\)</span> tosses it will almost always be close to <span class="arithmatex">\(0.5\)</span>. In deep learning, this explains why large batches produce more stable gradient estimates than small batches.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>See the video for a visual intuition and origins where the <a href="https://www.youtube.com/watch?v=cy8r7WSuT1I">normal distribution formula</a> comes from.</p>
</div>
<p>In deep learning, we often model a random vector: $
X \in \mathbb{R}^n.$ The most important distribution over vectors is the <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">multivariate normal</a> distribution:
$$
X \sim \mathcal{N}(\mu,\Sigma),
$$
where <span class="arithmatex">\(\mu \in \mathbb{R}^n\)</span> is the mean vector and <span class="arithmatex">\(\Sigma \in \mathbb{R}^{n\times n}\)</span> is the covariance matrix. The probability density function is:</p>
<div style="overflow-x:auto; max-width:100%;">
$$
\mathcal{N}(x;\mu,\Sigma)
=
\frac{1}{\sqrt{(2\pi)^n \det(\Sigma)}}
\exp\Big(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\Big).
$$
</div>

<p>The covariance matrix <span class="arithmatex">\(\Sigma\)</span> determines the <em>shape</em> of the Gaussian distribution. If different dimensions are correlated, the distribution becomes tilted, if variances are large, the distribution becomes wide.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A very common special case is the <strong>isotropic</strong> normal, where all dimensions have the same variance and are uncorrelated: 
$$
\Sigma = \sigma^2 I.
$$
In this case, the density calculation simplifies to <span class="arithmatex">\(\Sigma^{-1} = \frac{1}{\sigma^2}I\)</span> and <span class="arithmatex">\(\det(\Sigma) = (\sigma^2)^n\)</span>. The exponent also becomes proportional to the squared Euclidean distance <span class="arithmatex">\(\|x-\mu\|^2\)</span>. These all are extremely useful in deep learning because the computations become fast and stable even in high dimensions.</p>
<p>A slightly more flexible assumption is a <strong>diagonal</strong> normal:
$$
\Sigma =
\mathrm{diag}(\sigma_1^2,\sigma_2^2,\dots,\sigma_n^2),
$$
which allows each dimension to have its own variance but still avoids expensive full matrix inversion.</p>
<p>Finally, it is often convenient to use the <strong>precision matrix</strong>, defined as:
$$
\beta = \Sigma^{-1}.
$$
Precision describes the same uncertainty information as covariance, but it appears directly in the Gaussian exponent and is often easier to use in derivations.</p>
</div>
<h3 id="exponential">Exponential</h3>
<p><a href="https://www.acsu.buffalo.edu/~adamcunn/probability/exponential.html">Exponential distribution</a> models the waiting time until an event happens. It is defined on <span class="arithmatex">\(x \ge 0\)</span> and is parameterized by a rate <span class="arithmatex">\(\lambda &gt; 0\)</span>:
$$
p(x;\lambda) = \lambda e^{-\lambda x},
\qquad x \ge 0.
$$</p>
<div class="admonition success">
<p class="admonition-title">Exercise</p>
<p>Derive the expectation and variance of the exponential distribution.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A key property of the exponential distribution is the <strong>memoryless</strong> property:
$$
P(X &gt; s+t \mid X &gt; s) = P(X &gt; t).
$$
This means that if we have already waited <span class="arithmatex">\(s\)</span> time units, the remaining waiting time still follows the same distribution.</p>
</div>
<h3 id="laplace">Laplace</h3>
<p><a href="https://www.acsu.buffalo.edu/~adamcunn/probability/laplace.html">Laplace distribution</a> is a continuous distribution that resembles a normal distribution but has a sharper peak and heavier tails. It is defined as:
$$
p(x;\mu,b)
=
\frac{1}{2b}
\exp\Big(-\frac{|x-\mu|}{b}\Big),
\qquad b&gt;0.
$$</p>
<p>Here, <span class="arithmatex">\(\mu\)</span> is the mean (center), and <span class="arithmatex">\(b\)</span> is a scale parameter controlling spread. Its variance is:
$$
\mathrm{Var}(X) = 2b^2.
$$</p>
<p>Laplace noise is often used when we want a model that is more tolerant to outliers than a Gaussian. It is also closely related to <span class="arithmatex">\(L_1\)</span> <a href="../../notebooks/04_regul_optim">regularization</a>: if we assume model parameters follow a Laplace prior, maximizing the posterior corresponds to an <span class="arithmatex">\(L_1\)</span> penalty, which encourages sparsity.</p>
<h3 id="dirac-delta-and-empirical-distribution">Dirac Delta and Empirical Distribution</h3>
<p>In deep learning, we often treat a dataset as if it defines a probability distribution. But a dataset is finite: it contains only a limited set of observed points. To represent such a distribution mathematically, we use the <a href="https://en.wikipedia.org/wiki/Dirac_delta_function">Dirac delta function</a>.</p>
<figure>
  <img src="../../assets/images/probability/dirac.png" alt="Dirac delta distribution standard deviation" style="max-width: 80%; height: auto;">
  <figcaption style="margin-top: 0.5em; font-size: 0.9em; opacity: 0.85;">
    Schematic representation of the Dirac delta function. The height of the arrow is usually meant to specify the value of any multiplicative constant, which will give the area under the function. ~ <a href="//commons.wikimedia.org/wiki/User:Qef" title="User:Qef">Qef</a>, <a href="https://creativecommons.org/licenses/by-sa/3.0" title="Creative Commons Attribution-Share Alike 3.0">CC BY-SA 3.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=4308538">Link</a>
  </figcaption>
</figure>

<p>The Dirac delta <span class="arithmatex">\(\delta(x)\)</span> is not a normal function, but a mathematical object (a distribution) that behaves like a probability density concentrated at a single point. It satisfies:</p>
<ul>
<li><span class="arithmatex">\(\delta(x) = 0\)</span> for all <span class="arithmatex">\(x \ne 0\)</span></li>
<li><span class="arithmatex">\(\int_{-\infty}^{\infty} \delta(x)\,dx = 1\)</span></li>
</ul>
<p>More generally, a delta centered at a point <span class="arithmatex">\(a\)</span> is written as <span class="arithmatex">\(\delta(x-a)\)</span> and satisfies:
$$
\int_{-\infty}^{\infty} \delta(x-a)\,dx = 1.
$$</p>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>The notation <span class="arithmatex">\(\delta(x-a)\)</span> does not mean ordinary subtraction inside a normal function. It simply means a <em>Dirac delta distribution centered at <span class="arithmatex">\(a\)</span></em>.  </p>
<p>Intuitively, <span class="arithmatex">\(\delta(x-a)\)</span> represents an "infinitely sharp spike" located exactly at <span class="arithmatex">\(x=a\)</span>, with total area <span class="arithmatex">\(1\)</span>.  This is why it behaves like a tool that extracts the value of a function at <span class="arithmatex">\(a\)</span>:
$$
\int_{-\infty}^{\infty} f(x)\,\delta(x-a)\,dx = f(a).
$$</p>
<p>So <span class="arithmatex">\(\delta(x-a)\)</span> is best understood as "a delta located at <span class="arithmatex">\(a\)</span>".</p>
</div>
<h3 id="empirical">Empirical</h3>
<p>Suppose we have a dataset of <span class="arithmatex">\(m\)</span> samples:
$$
{x^{(1)}, x^{(2)}, \dots, x^{(m)}}.
$$</p>
<p><a href="https://en.wikipedia.org/wiki/Empirical_distribution_function">Empirical distribution</a> <span class="arithmatex">\(\hat{p}(x)\)</span> is defined as:
$$
\hat{p}(x)
=
\frac{1}{m}
\sum_{i=1}^{m} \delta(x-x^{(i)}).
$$</p>
<p>This means that the dataset assigns equal probability mass <span class="arithmatex">\(\frac{1}{m}\)</span> to every observed sample.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The empirical distribution in machine learning represents the distribution we actually train on. When we minimize training loss, we are minimizing an expectation under <span class="arithmatex">\(\hat{p}(x)\)</span> rather than under the true unknown distribution <span class="arithmatex">\(p(x)\)</span>.</p>
</div>
<p>The empirical expectation of a function <span class="arithmatex">\(f(x)\)</span> is:</p>
<div style="overflow-x:auto; max-width:100%;">
$$
\mathbb{E}[f(X)]
=
\int f(x)\,\hat{p}(x)\,dx
=
\frac{1}{m}\sum_{i=1}^m f(x^{(i)}),
\qquad
X \sim \hat{p}.
$$
</div>

<p>So the standard dataset average used in deep learning is literally an expectation under the empirical distribution.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The empirical distribution is a discrete approximation of the true data-generating distribution. Training a neural network is essentially an attempt to learn a model that generalizes beyond <span class="arithmatex">\(\hat{p}(x)\)</span> and performs well on the true distribution <span class="arithmatex">\(p(x)\)</span>.</p>
</div>
<h3 id="mixture-distributions">Mixture Distributions</h3>
<p><a href="https://en.wikipedia.org/wiki/Mixture_distribution">Mixture distribution</a> is a probability distribution formed by combining multiple simpler distributions. The idea is that the data may come from several different underlying sources, and each source has its own distribution. Suppose we have <span class="arithmatex">\(K\)</span> component distributions:
$$
p_1(x), p_2(x), \dots, p_K(x),
$$
and mixture weights:
$$
\pi_1,\pi_2,\dots,\pi_K,
\qquad
\pi_k \ge 0,
\qquad
\sum_{k=1}^K \pi_k = 1.
$$</p>
<p>Then the mixture distribution is:
$$
p(x)
=
\sum_{k=1}^K \pi_k p_k(x).
$$</p>
<p>This can be interpreted as a two-step sampling process:</p>
<ol>
<li>First sample a component index:
   $
   Z \sim \mathrm{Categorical}(\pi_1,\dots,\pi_K).
   $</li>
<li>Then sample from the corresponding component distribution:
   $
   X \sim p_Z(x).
   $</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The variable <span class="arithmatex">\(Z\)</span> is called a <a href="../../07_vae">latent variable</a> because it is not directly observed, but it explains which component generated the data.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Mixture models are widely used in probabilistic modeling because many real-world datasets are multi-modal. For example, the distribution of human heights in a population is not perfectly Gaussian, because it is better approximated as a mixture of two Gaussians (male and female). Similarly, pixel intensities in images often come from mixtures of different object materials, lighting conditions, and textures.</p>
</div>
<figure>
  <img src="../../assets/images/probability/gmm.gif" alt="Gaussian Mixture Model (GMM)" style="max-width: 100%; height: auto;">
  <figcaption style="margin-top: 0.5em; font-size: 0.9em; opacity: 0.85;">
    An example of Gaussian Mixture in image segmentation with grey histogram ~ <a href="//commons.wikimedia.org/w/index.php?title=User:KazukiAmakawa&amp;action=edit&amp;redlink=1" class="new" title="User:KazukiAmakawa (page does not exist)">KazukiAmakawa</a> - <span class="int-own-work" lang="en">Own work</span>, <a href="https://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons Attribution-Share Alike 4.0">CC BY-SA 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=75542622">Link</a>
  </figcaption>
</figure>

<p>The most common mixture model is the <a href="https://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model">Gaussian mixture model (GMM)</a>:
$$
p(x)
=
\sum_{k=1}^K \pi_k \mathcal{N}(x;\mu_k,\Sigma_k).
$$</p>
<p>Each component is a Gaussian with its own mean <span class="arithmatex">\(\mu_k\)</span> and covariance matrix <span class="arithmatex">\(\Sigma_k\)</span>. GMMs are expressive enough to approximate many complex distributions, while still being mathematically tractable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Mixture models are a natural step toward deep generative models. Many modern models (including <a href="../../notebooks/07_vae">VAEs</a> and <a href="../../notebooks">diffusion models</a>) can be viewed as learning complex mixtures in high-dimensional spaces.</p>
</div>
<h2 id="common-functions">Common Functions</h2>
<p>Deep learning models often output unconstrained real numbers. However, many probabilistic parameters must satisfy constraints such as being in <span class="arithmatex">\((0,1)\)</span> or summing to <span class="arithmatex">\(1\)</span>. For this reason, we use special nonlinear functions that map real-valued inputs into valid probability domains. The most common functions are described below.</p>
<h3 id="sigmoid">Sigmoid</h3>
<p>The <a href="../../notebooks/02_neural_network">logistic (sigmoid)</a> function maps any real number to <span class="arithmatex">\((0,1)\)</span>:
$$
\sigma(x)
=
\frac{1}{1+e^{-x}}
=
\frac{\exp(x)}{\exp(x)+\exp(0)}.
$$</p>
<p>It is widely used to parameterize Bernoulli probabilities:
$$
\phi = \sigma(z),
\qquad
Y \sim \mathrm{Bernoulli}(\phi).
$$</p>
<figure>
  <img src="../../assets/images/probability/sigmoid.svg" alt="Sigmoid function" style="max-width: 80%; height: auto;">
  <figcaption style="margin-top: 0.5em; font-size: 0.9em; opacity: 0.85;">
   The logistic (sigmoid) curve ~ <a href="//commons.wikimedia.org/wiki/User:Qef" title="User:Qef">Qef</a> (<a href="//commons.wikimedia.org/wiki/User_talk:Qef" title="User talk:Qef">talk</a>) - Created from scratch with gnuplot, Public Domain, <a href="https://commons.wikimedia.org/w/index.php?curid=4310325">Link</a>
  </figcaption>
</figure>

<p>Sigmoid is <a href="../01_calculus">differentiable</a> and also satisfies the symmetry identity:
$$
1-\sigma(x)=\sigma(-x).
$$</p>
<p>Its inverse function is called the <a href="../../notebooks/06_nn_ngram">logit</a>:
$$
\forall x \in (0,1),
\qquad
\sigma^{-1}(x)
=
\log\Big(\frac{x}{1-x}\Big).
$$</p>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>Sigmoid <strong>saturates</strong> for large <span class="arithmatex">\(|x|\)</span>. When <span class="arithmatex">\(x \gg 0\)</span>, <span class="arithmatex">\(\sigma(x)\approx 1\)</span>, and when <span class="arithmatex">\(x \ll 0\)</span>, <span class="arithmatex">\(\sigma(x)\approx 0\)</span>. In both cases, the gradient <span class="arithmatex">\(\frac{d}{dx}\sigma(x)\)</span> becomes close to <span class="arithmatex">\(0\)</span>, which slows down learning due to <a href="../../notebooks/04_regul_optim">vanishing gradients</a>.   For this reason, sigmoid is rarely used as a hidden-layer activation in modern deep networks, and is usually replaced by ReLU or its variants.</p>
</div>
<div class="admonition success">
<p class="admonition-title">Exercise</p>
<p>Find the derivative of the sigmoid function.</p>
</div>
<h3 id="relu">ReLU</h3>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>ReLU is not a probability concept. It does not parameterize a probability distribution and does not map values into a valid probability domain. It is primarily an activation function used in neural network architectures to improve optimization and gradient flow. We mention it here only because sigmoid saturation motivates why modern deep networks typically use ReLU-like activations in hidden layers.</p>
</div>
<p>The <a href="https://en.wikipedia.org/wiki/Rectified_linear_unit">rectified linear unit (ReLU)</a> is the most commonly used activation function in modern deep learning. It is defined as:
$$
\mathrm{ReLU}(x)=\max(0,x).
$$</p>
<p>ReLU is popular because it is simple, fast to compute, and avoids the strong saturation effect of sigmoid and <a href="https://en.wikipedia.org/wiki/Activation_function">tanh</a>.</p>
<figure>
  <img src="../../assets/images/probability/relu.svg" alt="ReLU function" style="max-width: 80%; height: auto;">
  <figcaption style="margin-top: 0.5em; font-size: 0.9em; opacity: 0.85;">
    Plot of the ReLU (blue) and <a href='https://en.wikipedia.org/wiki/Rectified_linear_unit#Gaussian-error_linear_unit_(GELU)'>GELU</a> (green) functions near x = 0 ~ <a href="//commons.wikimedia.org/w/index.php?title=User:Ringdongdang&amp;action=edit&amp;redlink=1" class="new" title="User:Ringdongdang (page does not exist)">Ringdongdang</a> - <span class="int-own-work" lang="en">Own work</span>, <a href="https://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons Attribution-Share Alike 4.0">CC BY-SA 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=95947821">Link</a>
  </figcaption>
</figure>

<p>ReLU is piecewise linear, so its derivative is simple:
$$
\frac{d}{dx}\mathrm{ReLU}(x)
=
\begin{cases}
0, &amp; x &lt; 0, \\
1, &amp; x &gt; 0.
\end{cases}
$$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ReLU is not differentiable at <span class="arithmatex">\(x=0\)</span>. However, researchers eventually realized that, this is not a practical issue in deep learning, because <span class="arithmatex">\(x=0\)</span> occurs with probability nearly zero for continuous-valued activations. In implementations, the gradient at <span class="arithmatex">\(0\)</span> is usually defined as <span class="arithmatex">\(0\)</span> (a valid subgradient choice).</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>ReLU has zero gradient for all negative inputs. If a neuron consistently outputs negative values, it may stop learning completely. This is called the <strong>dying ReLU</strong> problem. Variants such as <em>Leaky ReLU</em> and <em>GELU</em> are often used to reduce this effect.</p>
</div>
<h3 id="softplus">Softplus</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Softplus">softplus</a> function maps <span class="arithmatex">\(\mathbb{R}\)</span> to <span class="arithmatex">\((0,\infty)\)</span>:
$$
\zeta(x)
=
\log(1+\exp(x)).
$$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Softplus is useful when a model parameter must be strictly positive (e.g variance <span class="arithmatex">\(\sigma^2 &gt; 0\)</span>).</p>
</div>
<figure>
  <img src="../../assets/images/probability/softplus.svg" alt="Softplus function" style="max-width: 80%; height: auto;">
  <figcaption style="margin-top: 0.5em; font-size: 0.9em; opacity: 0.85;">
    Plot of the softplus function and the <a href='https://en.wikipedia.org/wiki/Ramp_function'>ramp function</a> ~ <a href="//commons.wikimedia.org/wiki/User:Nbarth" title="User:Nbarth">Nbarth</a> - This <a href="https://en.wikipedia.org/wiki/vector_image" class="extiw" title="w:vector image">vector image</a> includes elements that have been taken or adapted from this file:, <a href="http://creativecommons.org/publicdomain/zero/1.0/deed.en" title="Creative Commons Zero, Public Domain Dedication">CC0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=150411524">Link</a>
  </figcaption>
</figure>

<p>Softplus is closely connected to sigmoid. In particular:
$$
\log \sigma(x) = -\zeta(-x).
$$</p>
<p>And its derivative is exactly sigmoid:</p>
<div style="overflow-x:auto; max-width:100%;">
$$
\frac{d}{dx}\zeta(x)
=
\frac{d}{dx}\log(1+\exp(x))
=
\frac{\exp(x)}{1+\exp(x)}
=
\sigma(x).
$$
</div>

<p>This is a useful fact in deep learning: softplus behaves like a smooth version of ReLU, but its gradient changes smoothly between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. The inverse of softplus is:
$$
\forall x&gt;0,
\qquad
\zeta^{-1}(x)=\log(\exp(x)-1).
$$</p>
<p>A useful symmetry identity is:
$$
\zeta(x)-\zeta(-x)=x.
$$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In practice, we rarely implement softplus as <span class="arithmatex">\(\log(1+\exp(x))\)</span> directly, because <span class="arithmatex">\(\exp(x)\)</span> can overflow for large <span class="arithmatex">\(x\)</span>. Instead, deep learning libraries use numerically stable implementations.  </p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>PyTorch provides:
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
which computes softplus safely even when <span class="arithmatex">\(x\)</span> has large magnitude.</p>
</div>
<p>Softplus is commonly used when a model must output a strictly positive parameter (such as a variance), since it guarantees positivity while still being smooth and differentiable.</p>
</div>
<h3 id="logarithm">Logarithm</h3>
<p>Recall that the <a href="https://en.wikipedia.org/wiki/Logarithm">logarithm</a> function <span class="arithmatex">\(\log(x)\)</span> transforms products into sums. If we have independent samples, probabilities multiply:
$$
P(x^{(1)},\dots,x^{(m)})
=
\prod_{i=1}^m P(x^{(i)}).
$$</p>
<p>Taking the logarithm converts this product into a sum:
$$
\log P(x^{(1)},\dots,x^{(m)})
=
\sum_{i=1}^m \log P(x^{(i)}).
$$</p>
<p>This is the main reason why, say, <a href="../05_prob_modeling">maximum likelihood estimation</a> is almost always performed using the <strong>log-likelihood</strong> instead of the raw likelihood.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In machine learning, model parameters are often learned by <strong>maximum likelihood estimation (MLE)</strong>.  We choose parameters <span class="arithmatex">\(\theta\)</span> that make the observed dataset most probable under the model. Suppose we have i.i.d. samples:
$$
D={y^{(1)},\dots,y^{(m)}}.
$$</p>
<p>The likelihood of the dataset is:
$$
p(D \mid \theta)
=
\prod_{i=1}^{m} p!\big(y^{(i)} \mid \theta\big).
$$</p>
<p>The MLE estimate <span class="arithmatex">\(\hat{\theta}_{\mathrm{MLE}}\)</span> is defined as the value of <span class="arithmatex">\(\theta\)</span> that maximizes this likelihood. In practice we maximize the log-likelihood instead:
$$
\log p(D \mid \theta)
=
\sum_{i=1}^{m} \log p!\big(y^{(i)} \mid \theta\big).
$$</p>
</div>
<div class="admonition success">
<p class="admonition-title">Exercise</p>
<p>Suppose we observe <span class="arithmatex">\(m\)</span> i.i.d. samples <span class="arithmatex">\(y^{(1)},\dots,y^{(m)}\)</span> from a Bernoulli distribution with parameter <span class="arithmatex">\(\theta\)</span>.
Write the likelihood function <span class="arithmatex">\(L(\theta \mid y^{(1)},\dots,y^{(m)})\)</span> as a product.
Then rewrite it as a log-likelihood (a sum).</p>
</div>
<p>The logarithm is only defined for <span class="arithmatex">\(x&gt;0\)</span>. In particular:
$$
\log(0) = -\infty
$$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This matters in deep learning because losses often contain <span class="arithmatex">\(\log(p)\)</span> terms. If a model assigns probability <span class="arithmatex">\(p=0\)</span> to the true outcome, the loss becomes infinite. In practice, this is handled by using numerically stable implementations (computing loss from logits) or by clamping probabilities with a small constant <span class="arithmatex">\(\epsilon&gt;0\)</span>:
$$
\log(p) \;\;\to\;\; \log(\max(p,\epsilon)).
$$</p>
</div>
<figure>
  <img src="../../assets/images/probability/log.png" alt="Log functions" style="max-width: 80%; height: auto;">
  <figcaption style="margin-top: 0.5em; font-size: 0.9em; opacity: 0.85;">
    Plots of logarithm functions, with three commonly used bases. ~ Richard F. Lyon - made myself, alt version of Logarithm plots.svg with better text, <a href="https://creativecommons.org/licenses/by-sa/3.0" title="Creative Commons Attribution-Share Alike 3.0">CC BY-SA 3.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=13257335">Link</a>
  </figcaption>
</figure>

<p>Logarithm is strictly increasing (monotonic):
$$
x_1 &lt; x_2
\quad\Rightarrow\quad
\log(x_1) &lt; \log(x_2).
$$</p>
<p>Therefore, maximizing <span class="arithmatex">\(P(x)\)</span> is equivalent to maximizing <span class="arithmatex">\(\log P(x)\)</span>:
$$
\arg\max_x P(x)
=
\arg\max_x \log P(x).
$$</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The derivative of log is <span class="arithmatex">\(\frac{1}{x}.\)</span> This derivative becomes very large when <span class="arithmatex">\(x\)</span> is close to <span class="arithmatex">\(0\)</span>, which is one reason why log strongly penalizes assigning very small probability to true outcomes.</p>
</div>
<h3 id="softmax">Softmax</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a> function maps logits <span class="arithmatex">\(z\in\mathbb{R}^k\)</span> into a probability vector <span class="arithmatex">\(p\in\mathbb{R}^k\)</span>:
$$
p
=
\mathrm{softmax}(z_i)
=
\frac{\exp(z_i)}{\sum_{j=1}^{k} \exp(z_j)}.
$$</p>
<p>Softmax is also invariant to adding the same constant to all logits:
$$
\mathrm{softmax}(z)=\mathrm{softmax}(z+c).
$$</p>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>For numerical stability, softmax is usually computed as:
$$
\mathrm{softmax}(z)
=
\frac{\exp(z-\max(z))}{\sum_{j=1}^k \exp(z_j-\max(z))}.
$$</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A logit is an unconstrained score in <span class="arithmatex">\((-\infty,\infty)\)</span> that becomes a probability only after applying a transformation. For binary classification:
$$
\phi=\sigma(z),
\qquad
z=\mathrm{logit}(\phi).
$$
For multiclass classification: 
$<span class="arithmatex">\(p=\mathrm{softmax}(z).\)</span>$</p>
<p>Working with logits is often preferred in deep learning because logits are numerically stable and easier to optimize than probabilities directly.</p>
</div>
<h2 id="measure-theory">Measure Theory</h2>
<p>When working with continuous probability distributions, some technical details require ideas from <a href="https://en.wikipedia.org/wiki/Measure_(mathematics)">measure theory</a>. In deep learning literature, we will encounter a few terms.</p>
<p>A set <span class="arithmatex">\(A\)</span> is said to have <strong>measure zero</strong> if its total "size" is zero under integration. For example, a single point has measure zero. Any countable set of points also has measure zero. For example, the set of all rational numbers has measure zero, even though it is infinite.</p>
<p>A property is said to hold <strong>almost everywhere</strong> if it holds everywhere except on a measure-zero set. This means the property may fail on some special cases, but those cases occupy negligible space and do not affect integrals.</p>
<p>This terminology matters because many results that are always true in discrete probability only hold <em>almost everywhere</em> in the continuous case. In practice, these exceptions can usually be ignored.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is why deep learning often ignores edge cases. For example, ReLU is not differentiable at <span class="arithmatex">\(x=0\)</span>, but this does not matter in practice because the probability of hitting exactly <span class="arithmatex">\(x=0\)</span> is almost zero for continuous-valued activations.</p>
</div>
<div class="footnote">
<hr />
<ol>
<li id="fn:kolmogorov">
<p>Kolmogorov, A.N. (1933, 1950). <a href="https://archive.org/details/foundationsofthe00kolm">Foundations of the theory of probability</a>. New York, US: Chelsea Publishing Company.&#160;<a class="footnote-backref" href="#fnref:kolmogorov" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:dutchbook">
<p>A <a href="https://en.wikipedia.org/wiki/Dutch_book_theorems">Dutch book argument</a> says that if your probability assignments are inconsistent, someone can design a set of bets that guarantees you lose money no matter what happens. For example, if you assign <span class="arithmatex">\(P(A)=0.6\)</span> and <span class="arithmatex">\(P(\neg A)=0.6\)</span>, then you are claiming both an event and its opposite are more likely than not. A bettor could sell you a bet on <span class="arithmatex">\(A\)</span> and also sell you a bet on <span class="arithmatex">\(\neg A\)</span>, and you would overpay in total, while only one of them can ever pay out. This guarantees a loss. The probability axioms prevent such contradictions.&#160;<a class="footnote-backref" href="#fnref:dutchbook" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:frequentist">
<p>A real coin is not infinitely thin, so in principle it could land on its edge. In practice this outcome is extremely rare, so it is usually ignored and the sample space is approximated as having only two outcomes.&#160;<a class="footnote-backref" href="#fnref:frequentist" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:marginal">
<p>The term <em>marginal</em> is said to come from the traditional way of computing these sums on paper: one writes the joint distribution in a table and records the row and column totals in the margins of the page.&#160;<a class="footnote-backref" href="#fnref:marginal" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:multinoulli">
<p>The term multinoulli was popularized by Murphy (2012) as a playful name meaning "many Bernoullis."&#160;<a class="footnote-backref" href="#fnref:multinoulli" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
<li id="fn:gauss">
<p>The distribution is called <em>Gaussian</em> because it was studied extensively by <a href="https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss">Carl Friedrich Gauss</a>, especially in connection with measurement errors.&#160;<a class="footnote-backref" href="#fnref:gauss" title="Jump back to footnote 6 in the text">&#8617;</a></p>
</li>
</ol>
</div>







  
  



  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../02_linear_algebra/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Linear Algebra">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Linear Algebra
              </div>
            </div>
          </a>
        
        
          
          <a href="../04_information/" class="md-footer__link md-footer__link--next" aria-label="Next: Information Theory">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Information Theory
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://shahaliyev.org/" target="_blank" rel="noopener" title="shahaliyev.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M399 384.2c-22.1-38.4-63.6-64.2-111-64.2h-64c-47.4 0-88.9 25.8-111 64.2 35.2 39.2 86.2 63.8 143 63.8s107.8-24.7 143-63.8M0 256a256 256 0 1 1 512 0 256 256 0 1 1-512 0m256 16a72 72 0 1 0 0-144 72 72 0 1 0 0 144"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/shahaliyev/csci4701" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://ada.edu.az/en/" target="_blank" rel="noopener" title="ada.edu.az" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M271.9 20.2c-9.8-5.6-21.9-5.6-31.8 0l-224 128c-12.6 7.2-18.8 22-15.1 36S17.5 208 32 208h32v208l-51.2 38.4C4.7 460.4 0 469.9 0 480c0 17.7 14.3 32 32 32h448c17.7 0 32-14.3 32-32 0-10.1-4.7-19.6-12.8-25.6L448 416V208h32c14.5 0 27.2-9.8 30.9-23.8s-2.5-28.8-15.1-36l-224-128zM400 208v208h-64V208zm-112 0v208h-64V208zm-112 0v208h-64V208zm80-112a32 32 0 1 1 0 64 32 32 0 1 1 0-64"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.sections", "navigation.expand", "navigation.top", "navigation.footer", "navigation.tabs", "content.code.copy", "content.code.annotate", "search.highlight", "search.suggest", "content.footnote.tooltips"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../assets/app/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>